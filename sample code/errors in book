
Errata
- 48 submitted: last submission 10 Dec 2015

Errata type: Code | Page number: 30

The text says "Let fbt2 be the winning polynomial of degree 2" but it is not shown how it is declared.

With fbt2 the author was referring to the polynomial of degree 2 and did not show the code explicitly as it is obvious after having shown how to fit the poly for 1d.

In the code file analyze_webstats.py, you can see how it is calculated:

train = sorted(shuffled[split_idx:])
fbt1 = sp.poly1d(sp.polyfit(xb[train], yb[train], 1))
fbt2 = sp.poly1d(sp.polyfit(xb[train], yb[train], 2))
fbt3 = sp.poly1d(sp.polyfit(xb[train], yb[train], 3))
fbt10 = sp.poly1d(sp.polyfit(xb[train], yb[train], 10))
fbt100 = sp.poly1d(sp.polyfit(xb[train], yb[train], 100))

Errata type: Code | Page number: 30

Line 8 in the first code snippet:

clf.fit(X, Y)

should be:

clf.fit(X_train,Y_train)

Errata type: Code | Page number: 35

# use numpy operations to get setosa features
is_setosa = (labels == 'setosa')

The variable labels is not defined earlier. Has to replace that code with:

is_setosa = (target == 0)

Another solution the author suggests is to add the following line before is_setosa = (labels == 'setosa')

target_names = data['target_names']
labels = target_names[target]

Errata type: Code | Page number: 54

Next to last code block; method body should be indented:
>>> import scipy as sp
>>> def dist_raw(v1, v2):
... delta = v1-v2
... return sp.linalg.norm(delta.toarray())

Errata type: Code | Page number: 55

Missing line where "dist" is set to "dist_raw". The method "dist_raw" is defined on the bottom of page 54, but then "dist" is used on page 55. Confusing. In the downloaded code, you can see the omitted line.

Errata type: Code | Page number: 58

This should have a line break before u'imagin':
s.stem("imagination")u'imagin'

 

Errata type: Code | Page number: 67

'comp.sys.ma c.hardware' should not have a space. This was in the results generated by the author: >>> print(len(train_data.filenames) 3414 The actual result is "4119" if the group name is fixed.

 

Errata type: Code | Page number: 68

"We now have a pool of 3,414..."
See previous error on Page 67. The errant space in the code causes the entire "comp.sys.mac.hardward" group to be skipped.

 

Note from the authors: Code for Chapter 6

As you might know, Twitter changes its API from time to time. When the authors edited the book, they asked Twitter whether they would release the data to ease this foreseeable pain point of our users. Unfortunately, this was not possible. Therefore, they have put all the book's code examples on GitHub, where they actively maintain it. In the case of chapter 6, Twitter changed its API in version 1.1 to now require user authentication. Willi has just pushed an updated version to the code that correctly handles the new API 1.1: https://github.com/luispedro/BuildingMachineLearningSystemsWithPython/tree/master/ch06

Errata type: Typo | Page number: 261

In the Books section the line: If you are interested in that aspect of machine learning, then we recommend Pattern Recognition and Machine Learning, C. Bishop , Springer Apply Italics to this.

Should be

If you are interested in that aspect of machine learning, then we recommend Pattern Recognition and Machine Learning, C. Bishop, Springer.

Errata type: Typo | Page number: 66

Line 18, For convenience, the dataset module also contains...

Should be

For convenience, the datasets module also contains...

Errata type: Typo | Page number: 13

The Text on the bottom of the page says "In this case, it's a one-dimensional array of five elements."

Should be

In this case, it's a one-dimensional array of six elements.

Errata type: Typo | Page number: 245

As we saw in Chapter 10, Computer Vision–Pattern Recognition Finding Related Posts, this can easily be done by changing the computation code feature.

Should be:

As we saw in Chapter 10, Computer Vision–Pattern Recognition, this can easily be done by changing the computation code feature.

Errata type: Typo | Page number: 247

We will now look back at Chapter 10, Computer Vision–Pattern Recognition Finding Related Posts.

Should be:

We will now look back at Chapter 10, Computer Vision–Pattern Recognition.

Errata type: Code | Page number: 194

X, Y = [],[] in read_ceps() function

Should be

X, y = [],[]

Errata type: Graphics | Page number: 127

The third formula should have a log in the last term like this.

C_{best}=arg max_{c \in C}log(P(C=c)) + \sum_klog(P(F_{k}|C=c))

Errata type: Graphics | Page number: 127

The second formula is as follows:

C_{best}=arg max_{c \in C}log(P(C=c)) + log(P(F_{1}|C=c)) + log(P(F_{2}|C=c))

Suggestion | Page number: 126

One of our readers has suggested the second formula to be given as follows: log(P(C) \cdot P(F_{1}|C) \cdot 
P(F_{2}|C))=log(P(C))+log(P(F_{1}|C))+log(P(F_{2}|C))

The original formula given in the book is, however, correct.

Errata type: Code | Page number: 76

Last line in code:
corpus = corpora.BleiCorpus('./data/ap/ap.dat', '/data/ap/vocab.txt')

should be

corpus = corpora.BleiCorpus('./data/ap/ap.dat', './data/ap/vocab.txt')

Errata type: Code | Page number: 14

In the codesnippet on the bottom array has five instead of six elements. So the result of the operations is different.

Errata type: Code | Page number: 71

z = (len(post[0]), post[0], dataset.target_names[post[1]]) for post in
post_group

Has a syntax error and can be fixed like this:

z = [(len(post[0]), post[0], dataset.target_names[post[1]]) for post in  
post_group]

Errata type: Code | Page number: 111

last code line: precision_recall_curve(y_test, clf.predict(X_test)

Should be

precision_recall_curve(y_test, clf.predict(X_test))

Errata type: Code | Page number: 110

false negative(FN) -> True negative(TN)
True negative(TN) -> False negative(FN)

that instance is said to be a false negative

Should be

that instance is said to be a true negative

Errata type: Code | Page number: 122

In the middle of page:

P(F2=1|C="pos") = 2/4 = 0.25

Should be:

P(F2=1|C="pos") = 2/4 = 0.5

Errata type: Code | Page number: 23

At the top of the page:

print(res) should be print(residuals)

Errata type: Code | Page number: 26

In the code snippet the before last line is :

print("Error inflection=%f" % (fa + fb_error))

when it should be the summation of two errors fa_error + fb_error not a function and an error

Correct code is:

print("Error inflection=%f" % (fa_error + fb_error))

Errata type: Code | Page number: 36

Accuracy  is simply the fraction of examples that the model classifies correctly:

best_acc = -1.0
for fi in xrange(features.shape[1]):
  # We are going to generate all possible threshold for this feature
  thresh = features[:,fi].copy()
  thresh.sort()
  # Now test all thresholds:
  for t in thresh:
    pred = (features[:,fi] > t)
    acc = (pred == virginica).mean()
    if acc > best_acc:
      best_acc = acc
      best_fi = fi
      best_t = t

The correct code should be:

Accuracy  is simply the fraction of examples that the model classifies correctly:

best_acc = -1.0
best_fi = -1.0
best_t = -1.0

for fi in xrange(features.shape[1]) :
    thresh = features[:, fi].copy()
    thresh.sort()

    for t in thresh:
        pred = (features[:,fi] > t)
        acc = (labels[pred] == 'virginica').mean()
        if acc > best_acc:
            best_acc = acc
            best_fi = fi
            best_t = t

Errata type: Typo | Page number: 37

If we run it on the whole data, the best model that we get is split on the petal length.

Should be:

If we run it on the whole data, the best model that we get is split on the petal width.

Errata type: Code | Page number: 38 | Location 818

"Training error" should be "Training accurancy" 

The author has also updated the code available on github

Errata type: Code | Page number: 22-23

Change from:


>>> print(res)

to

>>> print(residuals)

Errata type: Technical | Page number: 123

The last element in the first column should "text" instead of "awesome text". However the value of F1 will change to "1" from "0" because the tweet contains "awesome" and F1 denotes the number of times "awesome" appears in the tweet text.

Errata type: Code | Page number: 35


The first line in the last code snippet should change from
" if features[:,2] < 2: print 'Iris Setosa' " to " if fs[2] < 2: print 'Iris Setosa' "

Errata type: Code | Page number: 174


in first code, line 5,


use the following :
dataset = [[int(tok) for tok in line.strip().split()]
for line in GzipFile('retail.dat.gz')]


instead of

dataset = [[int(tok) for tok in ,line.strip().split()]
for line in GzipFile('retail.dat.gz')]

Errata type: Code | Page number: 177

use the following :

for item in itemset:
   consequent = frozenset([item])
   antecendent = itemset=consequent
   base = 0.0
   acount = 0.0
   ccount = 0.0

instead of

for item in itemset:
           antecendent = itemset-consequent
           base = 0.0
           # acount: antecedent count
           acount = 0.0

Errata type: Technical | Page number: 205


use the following :
'Ridler Calvard' method

instead of

'Ridley Calvard' method

Errata type: Code | Page number: 175

new_itemsets = []
for iset in itemsets:
for v in valid:
if v not in iset:
newset = = (ell | set([v_]))
c_newset = 0
for d in dataset:
if d.issuperset(c):
c_newset += 1
if c_newset > minsupport:
newsets.append(newset)

should be:
new_itemsets = []
for iset in itemsets:
for v in valid:
if v not in iset:
newset = = (iset | set([v]))
c_newset = 0
for d in dataset:
if d.issuperset(newset):
c_newset += 1
if c_newset > minsupport:
new_newsets.append(newset)

Type: Technical | Page: 188

Replace "only 4 out of 24 jazz songs have been correctly classifi ed—that is
only 16 percent"

with

"only 7 out of 24 jazz songs have been correctly classified - that is only
29 percent"

Errata type: Code | Page number: 67

correction:

vectorized = vectorizer.fit_transform(dataset.data)
should be
vectorized = vectorizer.fit_transform(train_data.data)

Errata type: Technical | Page number: 103, 104, 105

The graph on these pages should depict the dashed line as "test error" and not "train error".

 

Errata type: Code | Page number: 223

 

Solution: Use
>> from scipy.stats import pearsonr

instead of
>> from import scipy.stats import pearsonr

Errata type: Code | Page number: 209

use the following :
W = np.exp(-2.*(X**2+ Y**2))
# Normalize again to 0..1
W = W - W.min()
W = W / W.ptp()
W = W[:,:,None] # This adds a dummy third dimension to W

instead of

W = np.exp(-2.*(X**2+ Y**2))
# Normalize again to 0..1
W = W - C.min()
W = W / C.ptp()
W = C[:,:,None] # This adds a dummy third dimension to W

Errata type: Code | Page number: 194

On page 194, The indentation should be as follows:

def read_ceps(genre_list, base_dir=GENRE_DIR):
    X, Y = [], []
    for label, genre in enumerate(genre_list):
        for fn in glob.glob(os.path.join(base_dir, genre, "*.ceps.npy")):
            ceps = np.load(fn)
            num_ceps = len(ceps)
            X.append(
                np.mean(ceps[int(num_ceps / 10):int(num_ceps * 9 / 10)], axis=0))
            y.append(label)

    return np.array(X), np.array(y)

Errata type: Code | Page number: 168

use the following:

movie_likeness = np.zeros((nmovies,nmovies))


instead of

movie_likeness = np.zeros((nmovies,nmovies))
allms = np.ones(nmovies, bool)
cs = np.zeros(nmovies)

Errata type: Technical | Page number: 177

In the table, replace "13791" by "1379".

Errata type: Code |page-162

 

On page 162, replace "return x, xl" by "return xc, xl"

Errata type: Technical | Page number: 215

The text should be
"In this dataset, however, the texture is not a clear marker of the class." instead of
 
"In this dataset, however, the texture is a clear marker of the class."

Errata type: Code | Page number: 169

use the following:

def nn_movie(movie_likeness, reviews, uid, mid):
likes = movie_likeness[mid].argsort()
# reverse the sorting so that most alike are in
# beginning
likes = likes[::-1]
# returns the rating for the most similar movie available
for ell in likes:
if reviews[uid,ell] > 0:
return reviews[uid,ell]

instead of

def nn_movie(movie_likeness, reviews, uid, mid):
likes = movie_likeness[mid].argsort()
# reverse the sorting so that most alike are in
# beginning
likes = likes[::-1]
# returns the rating for the most similar movie available
for ell in likes:
if reviews[u,ell] > 0:
return reviews[u,ell]

Errata type: Code | Page number: 254

On page 254, under the Running jug on our cloud machine section, the sentence  "We can now download the data and code from Chapter 12, Computer Vision–Pattern
Recognition Finding Related Posts,as follows" and the code snippet after it should be removed.

Errata type: Code | Page number: 247

The code should read:

@TaskGenerator
def label_for(f):
    return f[:-(3+1+2)]
    # 3 for "jpg" 1 for the dot and 2 for the number

and then

labels = map(label_for, filenames)

Errata type: Technical | Page number: 31

Use "scikit-learn"

instead of "Scikits-learn"

Errata type: Code | Page number: 35

Use the following
"
def apply_model( example ):
if example[2] < 2: print 'Iris Setosa'
else: print 'Iris Virginica or Iris Versicolour'
"

instead of
"
if features[:,2] < 2: print 'Iris Setosa'
else: print 'Iris Virginica or Iris Versicolour'
"

Errata type: Typo | Page number: 92

 

Use "PostTypeId" instead of "PostType" in the table.

Errata type: Typo | Page number: 167

Use below
'NumPy ships with np.corrcoef, which computes correlations. '
instead of
'NumPy ships with np.corrcoeff, which computes correlations. '

Errata type: Code | Page number: 207

 

Use the following:
lena = mh.imread('lenna.jpg', as_grey=True)

instead of
im = mh.imread('lenna.jpg', as_grey=True)

Errata type:Typo | Page number: 107

Use the following:
'by replacing y with log(odds)'

instead of
'by replacing y with p'

Errata type:Code | Page number: 112

Use:

>>> medium = np.argsort(scores)[len(scores) / 2]

>>> thresholds = np.hstack(([0],thresholds[medium]))

>>> idx80 = precisions>=0.8

>>> print("P=%.2f R=%.2f thresh=%.2f" % \ (precision[idx80][0], recall[idx80][0], threshold[idx80][0]))

P=0.81 R=0.37 thresh=0.63

instead of

>>> thresholds = np.hstack(([0],thresholds[medium]))
>>> idx80 = precisions>=0.8
>>> print("P=%.2f R=%.2f thresh=%.2f" % \ (precision[idx80][0],
recall[idx80][0], threshold[idx80][0]))
P=0.81 R=0.37 thresh=0.63


Errata type:Typo | Page number: 93

Use:The PostTypeId attribute, for example, is necessary to distinguish between questions and answers. It will be not picked to serve as a feature, but we will need it to filter the data. 

instead of

"The PostType attribute, for example, is only necessary to distinguish
between questions and answers. Furthermore, we can distinguish between them
later by checking for the ParentId attribute. So, we keep it for questions
too, and set it to 1.

 

Type: Code Page: 99

# which we don't want to count
    link_count_in_code += len(link_match.findall(match_str))
    links = link_match.findall(s)
    link_count = len(links)
    link_count -= link_count_in_code
    html_free_s = re.sub(" +", " ", tag_match.sub('',
        code_free_s)).replace("\n", "")
    link_free_s = html_free_s

Type: Code Page: 99

The code snippet should be:
...

 links = link_match.findall(s)

 link_count = len(links)

 link_count -= link_count_in_code

 html_free_s = re.sub(" +", " ",

tag_match.sub('',  code_free_s)).replace("\n", "")

 link_free_s = html_free_s

 

 # remove links from text before counting words

 for link in links:

if link.lower().startswith("http://"):

              link_free_s = link_free_s.replace(link,'')
...

Page 131 type:graphics

The graph on this page should indicate the P/R AUC value as 67 percent

Page 207 type:typo

Use the following:
'Only about 5 percent of these values will be true.'
instead of
'Only 1 percent of these values will be true.'

Errata type: Technical Page 113

Use the following:
This means that we will detect only one in three good answers
instead of
This means that we will detect only one in three bad answers

Errata type: Technical Page 60

Use the following:
tf = float(doc.count(term))/sum(doc.count(w) for w in doc)
instead of
tf = float(doc.count(term))/sum(doc.count(w) for w in docset)
Errata type: Technical | Page 123 P(F1=1,F2=1) should equal to (3/4)(2/4)(4/6)+(0)(1)(2/6)=0.25 Also, for the awesome crazy tweet, the denominator for both should be 0.25 instead of 0.33

